# nlohmann/json Benchmarking and Exploration

This directory contains the exploration code, benchmark suite, and results for the [nlohmann/json](https://github.com/nlohmann/json) library, as part of a broader exploration of JSON parsing and serialization libraries in C++. The goal is to evaluate performance, usability, and other key aspects to determine suitability for specific use cases.

## Setup and Exploration Code
- **Basic Examples**: Simple programs to demonstrate JSON parsing and serialization are located in the `test/src` directory. These examples help in understanding the API and usage patterns of nlohmann/json.
- **Build Configuration**: The project uses CMake for build management, ensuring C++11 standard compliance with compilers like GCC or Clang. Instructions for compilation and execution are provided below.
- **Docker Environment**: A Dockerfile is included for containerized build and execution, ensuring a consistent testing environment. See the Dockerfile for setup details.

### Compilation and Execution
1. Ensure you have CMake and a C++11 compatible compiler installed.
2. Clone the repository and navigate to this directory.
3. Run the following commands to build the exploration code:
   ```
   mkdir build
   cd build
   cmake ..
   make
   ```
4. Execute the basic example:
   ```
   ./test/basic_example
   ```

### Docker Setup
To use the Docker environment for testing:
1. Build the Docker image:
   ```
   docker build -t json-exploration .
   ```
2. Run the container:
   ```
   docker run -it --rm json-exploration
   ```

## Benchmark Suite
A comprehensive benchmark suite using Google Benchmark has been implemented for nlohmann/json, covering common JSON operations:
- Parsing JSON strings of varying sizes.
- Serializing JSON objects to strings.
- Accessing and modifying JSON elements.

### Benchmark Implementation
- **Source Files**: Located in `benchmark/src/`, with individual files for each operation (e.g., `parse_benchmark.cpp`, `serialize_benchmark.cpp`).
- **Build Instructions**: Use the Makefile or CMake configuration in the `benchmark` directory to build the benchmarks.
  ```
  cd benchmark
  mkdir build
  cd build
  cmake ..
  make
  ```
- **Execution**: Run the benchmark executable to generate results. Results are saved in the `results` directory as CSV files (e.g., `json_results_run_1.csv`).

### Benchmark Results
- **Results Directory**: `results/` contains raw benchmark output files from multiple runs to account for variability.
- **Processed Averages**: A summary CSV file (`json_average.csv`) can be generated by processing the raw results with a Python script. This file includes per-operation averages for real_time, cpu_time, and iterations, as well as an overall average across all operations.
- **Processing Results**: Use the script located at `../../tools/benchmark/calculate_averages.py` to process results:
  ```
  python ../../tools/benchmark/calculate_averages.py results
  ```

## Performance Analysis
[Placeholder for detailed performance analysis once finalized. This section will include tables or graphs comparing throughput and latency for individual operations and overall performance.]

## Qualitative Analysis
The library will be evaluated based on the following criteria:
- **Ease of Use**: API design, intuitiveness, and learning curve.
- **Features**: Support for JSON features (e.g., parsing, serialization, binary formats).
- **Documentation**: Quality and completeness of official documentation.
- **Community Support**: Activity on GitHub, issue resolution, and updates.
- **Compatibility**: Support for C++11 standards and integration with modern C++ practices.

[Placeholder for detailed subjective analysis based on the above criteria.]

## Proof of Concept: JSON and Redis Integration
A proof of concept (POC) has been developed to demonstrate the integration of `nlohmann/json` with Redis, showcasing how JSON data can be used in a distributed environment. Located in the `poc/` directory, this POC includes:
- **JSON Data Handling**: Creating JSON objects, serializing them to strings, and deserializing them back to JSON for manipulation.
- **Redis Integration**: Using the `RedisKeyManager` class to store, retrieve, and update JSON formatted strings as key values in Redis, ensuring data integrity through proper locking mechanisms.
- **Build and Execution**: The POC is built and run using the provided Dockerfile and Makefile, ensuring a consistent environment for testing this integration.

To run the POC:
1. Build the Docker image for the POC:
   ```
   make poc
   ```
2. This command will build and run the POC, demonstrating JSON operations and Redis integration in the console output.

## Next Steps
- Finalize the analysis of benchmark data to evaluate performance metrics.
- Visualize results for clarity in documentation.
- Complete the qualitative analysis based on the comparison criteria.
- Update this README with detailed findings and conclusions.
- Explore further optimizations or additional features for the JSON-Redis integration POC, such as handling more complex JSON structures or enhancing performance with Redis operations.
